{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f58e0285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing sequence CCCATCTCITCAIIATCCCTGCTGTTGG: no thermodynamic data for neighbors 'II/II' available\n",
      "Error processing sequence GAYYTIGGITGYGGIIGIGGIRGITGG: no thermodynamic data for neighbors 'II/II' available\n",
      "Updated Excel file saved as 'C:/Users/Nelso/OneDrive/Documents/Thesis/data/up_cleanned_nodupes_v1.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqUtils import MeltingTemp as mt\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = 'C:/Users/Nelso/OneDrive/Documents/Thesis/data/'  # Update this with the path to your Excel file\n",
    "file = 'cleanned_nodupes_v1.xlsx'\n",
    "df = pd.read_excel(file_path + file, header=0)  # Use header=0 if column names are in the first row\n",
    "\n",
    "# Function to replace ambiguous bases for Tm min calculation (choose weaker bonds)\n",
    "def replace_ambiguous_min(sequence):\n",
    "    return sequence.upper().replace('N', 'A').replace('R', 'A').replace('Y', 'T')\\\n",
    "                           .replace('S', 'C').replace('W', 'A').replace('K', 'T')\\\n",
    "                           .replace('M', 'A').replace('B', 'T').replace('D', 'A')\\\n",
    "                           .replace('H', 'A').replace('V', 'A')\n",
    "\n",
    "# Function to replace ambiguous bases for Tm max calculation (choose stronger bonds)\n",
    "def replace_ambiguous_max(sequence):\n",
    "    return sequence.upper().replace('N', 'G').replace('R', 'G').replace('Y', 'C')\\\n",
    "                           .replace('S', 'G').replace('W', 'G').replace('K', 'G')\\\n",
    "                           .replace('M', 'C').replace('B', 'G').replace('D', 'G')\\\n",
    "                           .replace('H', 'C').replace('V', 'G')\n",
    "\n",
    "# Adjusted function to calculate minimum melting temperature\n",
    "def calculate_tm_min(sequence):\n",
    "    if pd.isnull(sequence):\n",
    "        return None\n",
    "    seq = Seq(replace_ambiguous_min(sequence))\n",
    "    return round(mt.Tm_Wallace(seq), 2)\n",
    "\n",
    "# Adjusted function to calculate maximum melting temperature\n",
    "def calculate_tm_max(sequence):\n",
    "    if pd.isnull(sequence):\n",
    "        return None\n",
    "    seq = Seq(replace_ambiguous_max(sequence))\n",
    "    try:\n",
    "        return round(mt.Tm_NN(seq), 2)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error processing sequence {sequence}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Apply the functions to calculate Tm min and Tm max for each sequence\n",
    "df['Tm min (째C)'] = df['Sequence'].apply(calculate_tm_min)\n",
    "df['Tm max (째C)'] = df['Sequence'].apply(calculate_tm_max)\n",
    "\n",
    "# Save the updated DataFrame back to an Excel file\n",
    "output_file = 'up_' + file\n",
    "output_file_path = file_path\n",
    "df.to_excel(output_file_path + output_file, index=False)\n",
    "\n",
    "print(f\"Updated Excel file saved as '{output_file_path + output_file}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed89a488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Excel file...\n",
      "Excel file loaded.\n",
      "Processing sequences...\n",
      "Processed 100 sequences...\n",
      "Processed 200 sequences...\n",
      "Processed 300 sequences...\n",
      "Processed 400 sequences...\n",
      "Processed 500 sequences...\n",
      "Processed 600 sequences...\n",
      "Processed 700 sequences...\n",
      "Processed 800 sequences...\n",
      "Processed 900 sequences...\n",
      "Processed 1000 sequences...\n",
      "Processed 1100 sequences...\n",
      "Processed 1200 sequences...\n",
      "Sequence processing complete.\n",
      "Saving to CSV files...\n",
      "Saving chunk 1 of 9...\n",
      "Chunk 1 saved as 'C:/Users/Nelso/OneDrive/Documents/Thesis/data/up_cleanned_nodupes_v1_part_1.csv'\n",
      "Saving chunk 2 of 9...\n",
      "Chunk 2 saved as 'C:/Users/Nelso/OneDrive/Documents/Thesis/data/up_cleanned_nodupes_v1_part_2.csv'\n",
      "Saving chunk 3 of 9...\n",
      "Chunk 3 saved as 'C:/Users/Nelso/OneDrive/Documents/Thesis/data/up_cleanned_nodupes_v1_part_3.csv'\n",
      "Saving chunk 4 of 9...\n",
      "Chunk 4 saved as 'C:/Users/Nelso/OneDrive/Documents/Thesis/data/up_cleanned_nodupes_v1_part_4.csv'\n",
      "Saving chunk 5 of 9...\n",
      "Chunk 5 saved as 'C:/Users/Nelso/OneDrive/Documents/Thesis/data/up_cleanned_nodupes_v1_part_5.csv'\n",
      "Saving chunk 6 of 9...\n",
      "Chunk 6 saved as 'C:/Users/Nelso/OneDrive/Documents/Thesis/data/up_cleanned_nodupes_v1_part_6.csv'\n",
      "Saving chunk 7 of 9...\n",
      "Chunk 7 saved as 'C:/Users/Nelso/OneDrive/Documents/Thesis/data/up_cleanned_nodupes_v1_part_7.csv'\n",
      "Saving chunk 8 of 9...\n",
      "Chunk 8 saved as 'C:/Users/Nelso/OneDrive/Documents/Thesis/data/up_cleanned_nodupes_v1_part_8.csv'\n",
      "Saving chunk 9 of 9...\n",
      "Chunk 9 saved as 'C:/Users/Nelso/OneDrive/Documents/Thesis/data/up_cleanned_nodupes_v1_part_9.csv'\n",
      "All data saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqUtils import MeltingTemp as mt\n",
    "from itertools import product\n",
    "\n",
    "# Load the Excel file\n",
    "print(\"Loading Excel file...\")\n",
    "file_path = 'C:/Users/Nelso/OneDrive/Documents/Thesis/data/'\n",
    "file = 'cleanned_nodupes_v1.xlsx'\n",
    "df = pd.read_excel(file_path + file, header=0)\n",
    "print(\"Excel file loaded.\")\n",
    "\n",
    "# Ambiguous base mapping to possible replacements\n",
    "ambiguous_base_map = {\n",
    "    'N': ['A', 'T', 'G', 'C'],\n",
    "    'R': ['A', 'G'],\n",
    "    'Y': ['C', 'T'],\n",
    "    'S': ['G', 'C'],\n",
    "    'W': ['A', 'T'],\n",
    "    'K': ['G', 'T'],\n",
    "    'M': ['A', 'C'],\n",
    "    'B': ['C', 'G', 'T'],\n",
    "    'D': ['A', 'G', 'T'],\n",
    "    'H': ['A', 'C', 'T'],\n",
    "    'V': ['A', 'C', 'G'],\n",
    "    'I': ['A']  # Handling 'I' by replacing it with 'A'; adjust as needed\n",
    "}\n",
    "\n",
    "def generate_sequences(sequence):\n",
    "    cleaned_sequence = sequence.upper().replace('I', 'A')  # Replace 'I' with 'A'; adjust as needed\n",
    "    positions = [ambiguous_base_map.get(base, [base]) for base in cleaned_sequence]\n",
    "    return [''.join(seq) for seq in product(*positions)]\n",
    "\n",
    "def calculate_tm(sequence, method):\n",
    "    seq = Seq(sequence)\n",
    "    if method == 'min':\n",
    "        return round(mt.Tm_Wallace(seq), 2)\n",
    "    elif method == 'max':\n",
    "        try:\n",
    "            return round(mt.Tm_NN(seq), 2)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error processing sequence {sequence}: {e}\")\n",
    "            return None\n",
    "\n",
    "# Function to save DataFrame to CSV, splitting into multiple files if necessary\n",
    "def save_to_csv(df, base_file_path, max_rows=1048576):\n",
    "    num_rows = len(df)\n",
    "    chunks = num_rows // max_rows + (1 if num_rows % max_rows > 0 else 0)\n",
    "    \n",
    "    for i in range(chunks):\n",
    "        print(f\"Saving chunk {i + 1} of {chunks}...\")\n",
    "        chunk_start = i * max_rows\n",
    "        chunk_end = min((i + 1) * max_rows, num_rows)  # Ensure we don't go beyond the DataFrame's length\n",
    "        chunk = df.iloc[chunk_start:chunk_end]\n",
    "        chunk_file = f\"{base_file_path}_part_{i + 1}.csv\"\n",
    "        chunk.to_csv(chunk_file, index=False)\n",
    "        print(f\"Chunk {i + 1} saved as '{chunk_file}'\")\n",
    "\n",
    "# Expanded DataFrame to hold sequence variants and their Tm calculations\n",
    "expanded_df_rows = []\n",
    "\n",
    "print(\"Processing sequences...\")\n",
    "for index, row in df.iterrows():\n",
    "    if pd.isnull(row['Sequence']):\n",
    "        continue\n",
    "    sequence_variants = generate_sequences(row['Sequence'])\n",
    "    for variant in sequence_variants:\n",
    "        tm_min = calculate_tm(variant, 'min')\n",
    "        tm_max = calculate_tm(variant, 'max')\n",
    "        expanded_df_rows.append({'Original Sequence': row['Sequence'], 'Sequence Variant': variant, 'Tm min (째C)': tm_min, 'Tm max (째C)': tm_max})\n",
    "    # Progress tracker\n",
    "    if (index + 1) % 100 == 0:\n",
    "        print(f\"Processed {index + 1} sequences...\")\n",
    "\n",
    "expanded_df = pd.DataFrame(expanded_df_rows)\n",
    "print(\"Sequence processing complete.\")\n",
    "\n",
    "# Save the updated DataFrame to CSV, handling large data by splitting into multiple files\n",
    "print(\"Saving to CSV files...\")\n",
    "save_to_csv(expanded_df, file_path + 'up_' + file[:-5])  # Remove '.xlsx' from the original file name for the base path\n",
    "print(\"All data saved to CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8ba5fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping sequence CCCATCTCITCAIIATCCCTGCTGTTGG due to error: no thermodynamic data for neighbors 'II/II' available\n",
      "Skipping sequence GACCTIGGITGCGGIIGIGGIAGITGG due to error: no thermodynamic data for neighbors 'II/II' available\n",
      "Skipping sequence GACCTIGGITGCGGIIGIGGIGGITGG due to error: no thermodynamic data for neighbors 'II/II' available\n",
      "Skipping sequence GACCTIGGITGTGGIIGIGGIAGITGG due to error: no thermodynamic data for neighbors 'II/II' available\n",
      "Skipping sequence GACCTIGGITGTGGIIGIGGIGGITGG due to error: no thermodynamic data for neighbors 'II/II' available\n",
      "Skipping sequence GACTTIGGITGCGGIIGIGGIAGITGG due to error: no thermodynamic data for neighbors 'II/II' available\n",
      "Skipping sequence GACTTIGGITGCGGIIGIGGIGGITGG due to error: no thermodynamic data for neighbors 'II/II' available\n",
      "Skipping sequence GACTTIGGITGTGGIIGIGGIAGITGG due to error: no thermodynamic data for neighbors 'II/II' available\n",
      "Skipping sequence GACTTIGGITGTGGIIGIGGIGGITGG due to error: no thermodynamic data for neighbors 'II/II' available\n",
      "Skipping sequence GATCTIGGITGCGGIIGIGGIAGITGG due to error: no thermodynamic data for neighbors 'II/II' available\n",
      "Skipping sequence GATCTIGGITGCGGIIGIGGIGGITGG due to error: no thermodynamic data for neighbors 'II/II' available\n",
      "Skipping sequence GATCTIGGITGTGGIIGIGGIAGITGG due to error: no thermodynamic data for neighbors 'II/II' available\n",
      "Skipping sequence GATCTIGGITGTGGIIGIGGIGGITGG due to error: no thermodynamic data for neighbors 'II/II' available\n",
      "Skipping sequence GATTTIGGITGCGGIIGIGGIAGITGG due to error: no thermodynamic data for neighbors 'II/II' available\n",
      "Skipping sequence GATTTIGGITGCGGIIGIGGIGGITGG due to error: no thermodynamic data for neighbors 'II/II' available\n",
      "Skipping sequence GATTTIGGITGTGGIIGIGGIAGITGG due to error: no thermodynamic data for neighbors 'II/II' available\n",
      "Skipping sequence GATTTIGGITGTGGIIGIGGIGGITGG due to error: no thermodynamic data for neighbors 'II/II' available\n",
      "Updated Excel file saved as 'C:/Users/Nelso/OneDrive/Documents/Thesis/data/up_cleanned_nodupes_v1.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqUtils import MeltingTemp as mt\n",
    "from itertools import product\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = 'C:/Users/Nelso/OneDrive/Documents/Thesis/data/'\n",
    "file = 'cleanned_nodupes_v1.xlsx'\n",
    "df = pd.read_excel(file_path + file, header=0)\n",
    "\n",
    "# Ambiguous base mappings\n",
    "ambiguous_bases = {\n",
    "    'N': ['A', 'T', 'G', 'C'],\n",
    "    'R': ['A', 'G'],\n",
    "    'Y': ['C', 'T'],\n",
    "    'S': ['G', 'C'],\n",
    "    'W': ['A', 'T'],\n",
    "    'K': ['G', 'T'],\n",
    "    'M': ['A', 'C'],\n",
    "    'B': ['C', 'G', 'T'],\n",
    "    'D': ['A', 'G', 'T'],\n",
    "    'H': ['A', 'C', 'T'],\n",
    "    'V': ['A', 'C', 'G']\n",
    "}\n",
    "\n",
    "def generate_sequences(sequence):\n",
    "    sequence = sequence.upper()\n",
    "    combinations = [ambiguous_bases.get(nuc, [nuc]) for nuc in sequence]\n",
    "    return [''.join(seq) for seq in product(*combinations)]\n",
    "\n",
    "def calculate_tm_avg(sequence, tm_type):\n",
    "    sequences = generate_sequences(sequence)\n",
    "    tm_values = []\n",
    "    for seq in sequences:\n",
    "        try:\n",
    "            if tm_type == 'min':\n",
    "                tm_values.append(mt.Tm_Wallace(Seq(seq)))\n",
    "            elif tm_type == 'max':\n",
    "                tm_values.append(mt.Tm_NN(Seq(seq)))\n",
    "        except ValueError as e:\n",
    "            # Skip sequences that cause errors\n",
    "            print(f\"Skipping sequence {seq} due to error: {e}\")\n",
    "            continue\n",
    "\n",
    "    if tm_values:  # Check if the list is not empty\n",
    "        return round(sum(tm_values) / len(tm_values), 2)\n",
    "    return None\n",
    "\n",
    "\n",
    "# Apply the function to calculate the average Tm min and Tm max for each sequence\n",
    "df['Tm_min'] = df['Sequence'].apply(lambda x: calculate_tm_avg(x, 'min'))\n",
    "df['Tm_max'] = df['Sequence'].apply(lambda x: calculate_tm_avg(x, 'max'))\n",
    "\n",
    "# Save the updated DataFrame to a CSV file\n",
    "output_file = ('primer_metadata.csv')  # Change the file extension to .csv\n",
    "output_file_path = file_path\n",
    "df.to_csv(output_file_path + output_file, index=False)\n",
    "\n",
    "print(f\"Updated CSV file saved as '{output_file_path + output_file}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305b370e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
